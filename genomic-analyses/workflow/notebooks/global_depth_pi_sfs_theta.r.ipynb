{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "library(tidyverse)\n",
    "library(wesanderson)\n",
    "library(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of data and sample sets\n",
    "\n",
    "All analyses in this notebook were performed separately on two different sample sets: \n",
    "\n",
    "1. _highErrorRemoved_: This sample set contains 515 samples from urban and rural habitats across 26 cities (25 cities for GLUE-LOW1 plus 20 samples from Toronto. 5 samples were removed due to having abnormaly high alignment error rates (as reported by `Qualimap`). \n",
    "2. _finalSamples_lowCovRemoved_: This sample set contains 432 samples across 26 cities. In addition to the 5 samples with high error rates above, and additional 83 samples with low coverage (< 0.31X) were removed since these were previously found to have low mapping % and lower than average SNP density when compared to remaining samples. \n",
    "\n",
    "The 20 Toronto samples were selected as follows:\n",
    "- 2 samples from each of 5 urban populations for a total of 10 urban plants\n",
    "- 5 samples from one rural population and 1 sample from each of 5 other populations. These samples come from the western Toronto transect only. We couldn't evenly sample rural populations because they weren't evenly sampled for the Toronto data. Total of 10 rural plants \n",
    "- All 20 plants downsampled by sampling 25% of their reads. Because initial coverage between these samples varied between ~7.5X and ~14X, downsampled coverages in GLUE should range from ~1.8X to 3.5X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global patterns of diversity and structure\n",
    "\n",
    "In this notebook, we'll analyze the output fron `ANGSD` run separately on both sample sets described above. The notebook contains the following analyses:\n",
    "\n",
    "1. Sequencing depth across all samples. This is mostly a check to see whether our maximum depth threshold used in genotype likelihoos and SFS estimation is reasonable.\n",
    "2. General shape of the SFS estimated using all sites, 4-fold sites, and 0-fold sites across the genome\n",
    "3. Genome-wide average pairwise genetic diversity (Theta<sub>pi</sub>) across all samples. Done for all sites, 4-fold sites, and 0-fold sites.\n",
    "4. PCA showing population clustering of all 495 samples using 4-fold sites only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequencing depth\n",
    "\n",
    "### Load in depth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_depth_df <- function(path){\n",
    "    \n",
    "    # Get name of folder with parameter combinations\n",
    "    sample_set <- str_split(path_dir(path), '/', simplify = TRUE)[1,1]\n",
    "\n",
    "    # Read in SFS\n",
    "    full_path <- paste0(inpath, '/', path)\n",
    "    depth_df <- suppressMessages(\n",
    "        read_delim(full_path, delim = '\\t', col_names = FALSE)) %>% \n",
    "    t() %>% \n",
    "    as.data.frame() %>% \n",
    "    rename('num_sites' = 'V1') %>% \n",
    "    mutate(cov = 1:n() - 1,\n",
    "           sample_set = sample_set)\n",
    "    return(depth_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath <- '../results/angsd/depth/'\n",
    "depth_df <- list.files(inpath, pattern = 'CM019101.1_\\\\w+_allSites.depthGlobal', recursive = TRUE) %>% \n",
    "  map_dfr(., load_depth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(depth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "The dataset as 20,000 rows. Each row represents the total number of sites with a total X coverage, for one or the other sample set (10,000 rows per sample set). The exception is bin 10,000, which represents the number of sites with coverage equal or greater than 10,000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histogram of sequencing coverage\n",
    "\n",
    "Plotting histogram of number of sites at each X coverage along chromosome 1.\n",
    "\n",
    "Red dashed line is the max depth cutoff used when estimating genotype likelihoods and the SFS. Sites with depth great than this cutoff were excluded. \n",
    "\n",
    "- This depth (1250X) was calculated as 2 x the mean coverage from qualimap (1.25X) x Number of samples (500)\n",
    "- I didn't bother recalculating max depth when we switched from 500 to 495 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depth_cutoff <- 1250\n",
    "depthGlobal_plot <- ggplot(depth_df, aes(x = cov, y = num_sites)) +\n",
    "    geom_bar(stat = 'identity', color = 'black', fill = 'white') + \n",
    "    xlab('Coverage') + ylab('Number of sites') +\n",
    "    facet_wrap(~sample_set) + \n",
    "    theme_classic() + \n",
    "    geom_vline(xintercept = depth_cutoff, linetype = 'dashed', color = 'red') +\n",
    "    theme(axis.text = element_text(size = 13),\n",
    "        axis.title = element_text(size = 15))\n",
    "depthGlobal_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate proportion of sites above and below cutoff for both sample sets\n",
    "total_sites <- sum(depth_df$num_sites, na.rm = TRUE)\n",
    "depth_df %>% \n",
    "    mutate(is_below_cutoff = ifelse(cov <= depth_cutoff, 1, 0)) %>% \n",
    "    group_by(sample_set, is_below_cutoff) %>% \n",
    "    summarize(n = sum(num_sites, na.rm = TRUE)) %>% \n",
    "    mutate(freq = n / sum(n, na.rm = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot\n",
    "outpath <- snakemake@output[[1]]\n",
    "print(outpath)\n",
    "ggsave(filename = outpath, plot = depthGlobal_plot, device = 'pdf', \n",
    "       dpi = 300, width = 14, height = 8, units = 'in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My take\n",
    "\n",
    "Regardless of sample set:\n",
    "- Most sites have 1 to 2X coverage\n",
    "- As coverage increases beyond 2X, there is a gradual decline in the number of sites for a given depth\n",
    "- 1250X is a reasonable cutoff and captures ~98% of all sites. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SFS and diversity\n",
    "\n",
    "Here I'll plot the SFS for all sites across the genome, in additional to subsets of degenerate sites (4-fold and 0-fold). We'll similarly estimate diversity as the genome-wide average of pairwise nucleotide differences for these same sets of sites. \n",
    "\n",
    "- Filters applied on on sites:\n",
    "    - Minimum phred-scaled read mapping quality of 30\n",
    "    - Minimimum phred-scaled base quality of 20\n",
    "    - Max depth of 1250X across all individuals\n",
    "    - 50% of all individuals required to have at least 1 read\n",
    "    \n",
    "In addition to the above filters, genotype likelihoods are estimated using the `samtools` model with the `samtools` \"extended BAQ\" algorithm to re-assign base quality scores around INDELS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SFS\n",
    "\n",
    "#### Load in SFS data as single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_long_sfs <- function(path){\n",
    "  \n",
    "    # Get name of folder with parameter combinations\n",
    "    dir <- str_split(path_dir(path), '/', simplify = TRUE)\n",
    "    sample_set <- dir[1, 1]\n",
    "    site <- dir[1, 2]\n",
    "\n",
    "    # Read in SFS\n",
    "    full_path <- paste0(inpath, '/', path)\n",
    "    sfs <- suppressMessages(read_delim(full_path, delim= '\\t', col_names = FALSE)) %>% \n",
    "    as.data.frame() %>% \n",
    "    rename('maf' = 'X1',\n",
    "           'num_sites' = 'X2') %>% \n",
    "    filter(num_sites != 0) %>%  #  folded SFS so samples > # of samples will be 0\n",
    "    mutate(prop_sites = num_sites / sum(num_sites),\n",
    "           sample_set = sample_set,\n",
    "           site = site)\n",
    "    return(sfs)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inpath <- '../results/angsd/sfs/'\n",
    "sfs_df <- list.files(inpath, pattern = '*allChroms.sfs', recursive = TRUE) %>% \n",
    "  map_dfr(., load_long_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at the da\n",
    "head(sfs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot SFS\n",
    "\n",
    "- Only plotting minor allele frequence from 1 to 25. Therefore, invariant sites and sites with MAF > 25/N not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sites in each category?\n",
    "sfs_df %>% \n",
    "    group_by(sample_set, site) %>% \n",
    "    summarize(total_sites = sum(num_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_plot <- sfs_df %>% \n",
    "    filter(maf != 0 & maf <= 25)  %>%\n",
    "    ggplot(., aes(x = maf, y = prop_sites)) + \n",
    "    geom_bar(stat ='identity', color = 'black',  width=.70) + \n",
    "    facet_grid(sample_set~ site) +\n",
    "    ylab('Proportion of sites') + xlab('Minor allele frequency') +\n",
    "    scale_fill_manual(values = cols) +\n",
    "    scale_x_continuous(breaks = seq(1, 40, 3)) +\n",
    "    scale_y_continuous(breaks = seq(0, 0.13, 0.02)) + \n",
    "    theme_classic() + \n",
    "    theme(axis.text = element_text(size = 13),\n",
    "        axis.title = element_text(size = 15))\n",
    "sfs_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot\n",
    "outpath <- snakemake@output[[2]]\n",
    "print(outpath)\n",
    "ggsave(filename = outpath, plot = sfs_plot, device = 'pdf', \n",
    "       dpi = 300, width = 12, height = 10, units = 'in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### My take\n",
    "\n",
    "- The allSites SFS look good\n",
    "- The 4-fold SFS look strange, especially for the *finalSamples_lowCovRemoved* sample set. They're not as \"smooth\" as I would have expected\n",
    "    - Is this a real result? Do we expect this when pooling samples from across the world with different demographic histories? \n",
    "- 0-fold SFS looks OK, though maybe a little jagged. It's more left-skewed than 4-fold SFS, as expected. \n",
    "- One quick note: There are about twice as many sites in the *finalSamples* dataset than the *highErrorRemoved* dataset, despite having about 83 fewer samples. \n",
    "    - I think this is because the proportion of individuals required to have reads at a site was fixed at 50%. For the *finalSamples* dataset, this equates to 216 samples, which is esily met in this dataset since bad individuals have already been removed. As a result, more sites pass this filter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Diversity\n",
    "\n",
    "#### Load in diversity dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_div_neut_df <- function(path){\n",
    "  \n",
    "    # Get name of folder with parameter combinations\n",
    "    dir <- str_split(path_dir(path), '/', simplify = TRUE)\n",
    "    sample_set <- dir[1, 1]\n",
    "    site <- dir[1, 2]\n",
    "\n",
    "    # Read in stats\n",
    "    full_path <- paste0(inpath, '/', path)\n",
    "    stats <- suppressMessages(read_delim(full_path, delim= '\\t', col_names = TRUE)) %>% \n",
    "    mutate(sample_set = sample_set,\n",
    "           site = site,\n",
    "           tp_scaled = tP / nSites,\n",
    "           tw_scaled = tW / nSites)\n",
    "    return(stats)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath <- '../results/angsd/summary_stats/thetas/'\n",
    "thetas_df <- list.files(inpath, pattern = '*diversityNeutrality.thetas.idx.pestPG', recursive = TRUE) %>% \n",
    "  map_dfr(., load_div_neut_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tp is theta_pi\n",
    "# tw is theta_waterson\n",
    "# td is Tajima's D\n",
    "thetas_df %>% \n",
    "  group_by(sample_set, site) %>% \n",
    "  summarise(total_sites = sum(nSites),\n",
    "            mean_tp = mean(tp_scaled),\n",
    "            mean_tw = mean(tw_scaled), \n",
    "            mean_td = mean(Tajima))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### My take\n",
    "\n",
    "Regardless of sample set:\n",
    "- Looks good. Lower diversity at 0-fold sites, as expected\n",
    "- ~1.5% genome-wide diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "\n",
    "- PCA is performed on genotype likelihoods\n",
    "- Filtering criteria the same as those above with one exception:\n",
    "    - This is based only on variant sites with MAF > 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in data and perform PCA\n",
    "\n",
    "- Perform PCA on both sample sets and merge into single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get PCA summary as matrix\n",
    "pca_importance <- function(x) {\n",
    "  vars <- x$sdev^2\n",
    "  vars <- vars/sum(vars)\n",
    "  rbind(`Standard deviation` = x$sdev, `Proportion of Variance` = vars, \n",
    "      `Cumulative Proportion` = cumsum(vars))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with habitat info\n",
    "habitat_info <- suppressMessages(\n",
    "    read_delim(\n",
    "        '../../sequencing-prep/resources/low1_sampleSheet.txt', \n",
    "                           delim = '\\t')) %>% \n",
    "    dplyr::select(continent, range, city, pop, individual, site, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### highErrorRemoved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load covariance matrix from PCAngsd\n",
    "cov_mat_highErrorRemoved <- suppressMessages(\n",
    "    read_delim(\n",
    "        '../results/population_structure/pcangsd/highErrorRemoved_4fold_maf0.05_pcangsd.cov', \n",
    "                      col_names = FALSE, delim = ' ')) %>% \n",
    "      as.matrix()\n",
    "\n",
    "# Combine continent and habitat data with sample order from ANGSD\n",
    "samples_highErrorRemoved <- suppressMessages(\n",
    "    read_table(\n",
    "        '../results/program_resources/angsd_highErrorRemoved_order.txt', col_names = FALSE) %>% \n",
    "  rename('sample' = 'X1')) %>%\n",
    "  left_join(., habitat_info, by = 'sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_importance(summary(princomp(cov_mat_highErrorRemoved))) %>% \n",
    "    as.data.frame() %>% \n",
    "    dplyr::select(Comp.1:Comp.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with eigenvectors\n",
    "eigenvectors_highErrorRemoved <- eigen(cov_mat_highErrorRemoved)\n",
    "eigen_df_highErrorRemoved <- eigenvectors_highErrorRemoved$vectors %>% \n",
    "    as.data.frame() %>% \n",
    "    dplyr::select(V1, V2, V3, V4) %>% \n",
    "    rename('PC1' = 'V1',\n",
    "         'PC2' = 'V2', \n",
    "         'PC3' = 'V3',\n",
    "         'PC4' = 'V4') %>% \n",
    "    bind_cols(., samples_highErrorRemoved) %>% \n",
    "    mutate(sample_set = 'highErrorRemoved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### finalSamples_lowCovRemoved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load covariance matrix from PCAngsd\n",
    "cov_mat_finalSamples <- suppressMessages(\n",
    "    read_delim(\n",
    "        '../results/population_structure/pcangsd/finalSamples_lowCovRemoved_4fold_maf0.05_pcangsd.cov', \n",
    "                      col_names = FALSE, delim = ' ')) %>% \n",
    "      as.matrix()\n",
    "\n",
    "# Combine continent and habitat data with sample order from ANGSD\n",
    "samples_finalSamples <- suppressMessages(\n",
    "    read_table(\n",
    "        '../results/program_resources/angsd_finalSamples_lowCovRemoved_order.txt', col_names = FALSE) %>% \n",
    "  rename('sample' = 'X1')) %>%\n",
    "  left_join(., habitat_info, by = 'sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_importance(summary(princomp(cov_mat_finalSamples))) %>% \n",
    "    as.data.frame() %>% \n",
    "    dplyr::select(Comp.1:Comp.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with eigenvectors\n",
    "eigenvectors_finalSamples <- eigen(cov_mat_finalSamples)\n",
    "eigen_df_finalSamples <- eigenvectors_finalSamples$vectors %>% \n",
    "    as.data.frame() %>% \n",
    "    dplyr::select(V1, V2, V3, V4) %>% \n",
    "    rename('PC1' = 'V1',\n",
    "         'PC2' = 'V2', \n",
    "         'PC3' = 'V3',\n",
    "         'PC4' = 'V4') %>% \n",
    "    bind_cols(., samples_finalSamples) %>% \n",
    "    mutate(sample_set = 'finalSamples_lowCovRemoved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join dataframes\n",
    "eigen_df <- bind_rows(eigen_df_highErrorRemoved, eigen_df_finalSamples)\n",
    "head(eigen_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Colored by habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "col1 <- wes_palette(\"Darjeeling1\", n = 5, type = 'discrete')[2]\n",
    "col2 <- wes_palette(\"Darjeeling1\", n = 5, type = 'discrete')[4]\n",
    "cols <- c(col1, col2)\n",
    "pca_byHabitat <- ggplot(eigen_df, aes(x = PC1, y = PC2, color = site, shape = site)) +\n",
    "    geom_point(size = 2) + \n",
    "    scale_color_manual(values = cols) + \n",
    "    facet_wrap(~sample_set) +\n",
    "    theme_classic() + \n",
    "    xlab('PC1') + ylab('PC2') +\n",
    "    theme(axis.text = element_text(size = 13),\n",
    "         axis.title = element_text(size = 15),\n",
    "         legend.position = 'top')\n",
    "pca_byHabitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot\n",
    "outpath <- snakemake@output[[3]]\n",
    "print(outpath)\n",
    "ggsave(filename = outpath, plot = pca_byHabitat, device = 'pdf', \n",
    "       dpi = 300, width = 14, height = 8, units = 'in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Colored by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "cols <- wes_palette(\"Darjeeling1\", n = 26, type = 'continuous')\n",
    "pca_byCity <- ggplot(eigen_df, aes(x = PC1, y = PC2, color = city, shape = site)) +\n",
    "    geom_point(size = 2) + \n",
    "    scale_color_manual(values = cols) + \n",
    "    facet_wrap(~sample_set) +\n",
    "    theme_classic() + \n",
    "    xlab('PC1') + ylab('PC2') +\n",
    "    theme(axis.text = element_text(size = 13),\n",
    "        axis.title = element_text(size = 15),\n",
    "        legend.position = 'top')\n",
    "pca_byCity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot\n",
    "outpath <- snakemake@output[[4]]\n",
    "print(outpath)\n",
    "ggsave(filename = outpath, plot = pca_byCity, device = 'pdf', \n",
    "       dpi = 300, width = 14, height = 8, units = 'in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Colored by continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "cols <- wes_palette(\"Darjeeling1\", n = 6, type = 'continuous')\n",
    "pca_byContinent <- ggplot(eigen_df, aes(x = PC1, y = PC2, color = continent, shape = site)) +\n",
    "    geom_point(size = 2) + \n",
    "    scale_color_manual(values = cols) + \n",
    "    facet_wrap(~sample_set) +\n",
    "    theme_classic() + \n",
    "    xlab('PC1') + ylab('PC2') +\n",
    "    theme(axis.text = element_text(size = 13),\n",
    "        axis.title = element_text(size = 15),\n",
    "        legend.position = 'top')\n",
    "pca_byContinent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot\n",
    "outpath <- snakemake@output[[5]]\n",
    "print(outpath)\n",
    "ggsave(filename = outpath, plot = pca_byContinent, device = 'pdf', \n",
    "       dpi = 300, width = 14, height = 8, units = 'in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Colored by range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "col1 <- wes_palette(\"Darjeeling1\", n = 5, type = 'discrete')[2]\n",
    "col2 <- wes_palette(\"Darjeeling1\", n = 5, type = 'discrete')[4]\n",
    "cols <- c(col1, col2)\n",
    "pca_byRange <- ggplot(eigen_df, aes(x = PC1, y = PC2, color = range, shape = site)) +\n",
    "    geom_point(size = 2) + \n",
    "    scale_color_manual(values = cols) + \n",
    "    facet_wrap(~sample_set) +\n",
    "    theme_classic() + \n",
    "    xlab('PC1') + ylab('PC2') +\n",
    "    theme(axis.text = element_text(size = 13),\n",
    "        axis.title = element_text(size = 15),\n",
    "        legend.position = 'top')\n",
    "pca_byRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot\n",
    "outpath <- snakemake@output[[6]]\n",
    "print(outpath)\n",
    "ggsave(filename = outpath, plot = pca_byRange, device = 'pdf', \n",
    "       dpi = 300, width = 14, height = 8, units = 'in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### My take\n",
    "\n",
    "- PCAs are the same, regardless of sample set\n",
    "    - Suggests we could use all samples for this analysis (N = 515).\n",
    "- PC2 seems to largely separate Introduced vs. Native range\n",
    "- Unclear what PC1 corresponds to (maybe related to something like Lat/Long?)\n",
    "- Urban/rural sites seem to be largely overlapping within cities with some exceptions (e.g., Thessaloniki). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
