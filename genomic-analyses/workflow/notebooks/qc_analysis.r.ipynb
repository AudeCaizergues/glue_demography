{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(wesanderson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC analysis and exploration of bad samples\n",
    "\n",
    "- Here we'll look at some of the QC output by Qualimap as part of the `multiqc` pipeline\n",
    "- We'll lokk at per-sample heterozygosity estimated from the single-sample SFS as a measure of genetic variation\n",
    "    - Samples with really weird diversity values might need to be looked into\n",
    "    \n",
    "- SFS were estimated in `ANGSD` with no filters (e.g., MQ, BQ) so that hopefully bad samples will be obvious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in SFS and multiQC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load folded SFS output by ANGSD. \n",
    "load_wide_sfs <- function(path){\n",
    "  \n",
    "  # Get name of folder with parameter combinations\n",
    "  dirname <- dirname(path)\n",
    "  \n",
    "  # Read in SFS\n",
    "  full_path <- paste0(inpath, '/', path)\n",
    "  sfs <- suppressMessages(read_table(full_path, col_names = FALSE)) %>% \n",
    "    as.data.frame() %>% \n",
    "    rename('Invar' = 'X1',\n",
    "           'Var' = 'X2') %>% \n",
    "    dplyr::select(-X3) %>% \n",
    "    mutate(Sample = dirname,\n",
    "           total_sites = Invar + Var,\n",
    "           prop_var = Var / total_sites)\n",
    "\n",
    "  return(sfs)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all SFS as single dataframe\n",
    "inpath <- '../results/single_sample_sfs/'\n",
    "sfs_df <- list.files(inpath, recursive = TRUE, pattern = '*.sfs$') %>% \n",
    "  map_dfr(., load_wide_sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Qualimap data from multiQC directory\n",
    "multiqc <- suppressMessages(read_delim('../results/qc/multiqc/multiqc_data/multiqc_qualimap_bamqc_genome_results_qualimap_bamqc.txt', \n",
    "                      delim='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all data into single df\n",
    "allQC_data <- multiqc %>% \n",
    "    mutate(Sample = str_extract(Sample, pattern = '\\\\w+_\\\\d+_\\\\d+$')) %>% \n",
    "    dplyr::select(Sample, mean_coverage, percentage_aligned, general_error_rate) %>% \n",
    "    left_join(., sfs_df, by = 'Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nrow(allQC_data))\n",
    "head(allQC_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show some plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histogram of mean coverage\n",
    "\n",
    "- Histogram of mean coverage reported by Qualimap\n",
    "- Vertical red line place at putative cutoff separating low coverage from higher coverage samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_hist <- allQC_data %>% \n",
    "    ggplot(., aes(x = mean_coverage)) +\n",
    "    geom_histogram(bins = 100, color = 'black', fill = 'white') + \n",
    "    geom_vline(xintercept = 0.35, color = 'red') +\n",
    "    xlab('Mean depth (X)') + ylab('Sample Count') +\n",
    "    theme_classic()\n",
    "cov_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath <- snakemake@output[[1]]\n",
    "ggsave(filename = outpath, plot = cov_hist, device = 'pdf', height = 8, width = 8, units = 'in', dpi = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General error rate histogram\n",
    "\n",
    "- Histogram of error rates reported by Qualimap\n",
    "- High error rates are problematic and can bias diversity upwards. \n",
    "- High error rates likely caused by different species being sequenced. \n",
    "- These samples should be removed right from the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_hist <- allQC_data %>% \n",
    "    ggplot(., aes(x = general_error_rate)) +\n",
    "    geom_histogram(bins = 100, color = 'black', fill = 'white') + \n",
    "    xlab('General alignment error rate (%)') + ylab('Sample Count') +\n",
    "    theme_classic()\n",
    "error_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath <- snakemake@output[[2]]\n",
    "ggsave(filename = outpath, plot = error_hist, device = 'pdf', height = 8, width = 8, units = 'in', dpi = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove high error rate samples\n",
    "\n",
    "- Will immediately remove high error rate samples from data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only samples with low error rates\n",
    "allQC_data_highErrorRemoved <- allQC_data %>% \n",
    "    filter(general_error_rate < 0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Alignment percent by coverage and SNP density\n",
    "\n",
    "- Plot Alignment percentage and sample coverage, colored by SNP density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### All samples (minus high error rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols <- wes_palette(\"Zissou1\", 100, type = \"continuous\")\n",
    "align_cov_SNPdens_allsamples_plot <- ggplot(data = allQC_data_highErrorRemoved, \n",
    "                                            aes(x = mean_coverage, y = percentage_aligned, color = prop_var)) + \n",
    "    scale_color_gradientn(colors = cols) +\n",
    "    xlab('Mean depth (X)') + ylab('Alignment %') + labs(color = 'SNP density') + \n",
    "    geom_vline(xintercept = 0.31, color = 'red') +\n",
    "    geom_point() +\n",
    "    theme_classic()\n",
    "align_cov_SNPdens_allsamples_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Some samples have very low alignemtn % and similarly low coverage\n",
    "    - These samples also have lower than average SNP density estimates\n",
    "- Overall, filtering on coverage would probably be a good start to removing these poorly sequenced samples. \n",
    "- Will use 0.31X as our cutoff, since this corresponds to a natural split in the mean coverage histogram (see coverage histogram above). \n",
    "    - Cutoff also shown in figure above. Samples to left of this line will get tossed for some analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath <- snakemake@output[[3]]\n",
    "ggsave(filename = outpath, plot = align_cov_SNPdens_allsamples_plot, device = 'pdf', \n",
    "       height = 8, width = 8, units = 'in', dpi = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Low coverage samples removed\n",
    "\n",
    "- Same histogram as above, but removing samples with coverage < 0.31X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only samples with higher coverage\n",
    "allQC_data_highQualOnly <- allQC_data_highErrorRemoved %>% \n",
    "    filter(mean_coverage >= 0.31)\n",
    "print(nrow(allQC_data_highQualOnly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols <- wes_palette(\"Zissou1\", 100, type = \"continuous\")\n",
    "align_cov_SNPdens_highQualOnly_plot <- ggplot(data = allQC_data_highQualOnly, \n",
    "                                            aes(x = mean_coverage, y = percentage_aligned, color = prop_var)) + \n",
    "    scale_color_gradientn(colors = cols) +\n",
    "    xlab('Mean depth (X)') + ylab('Alignment %') + labs(color = 'SNP density') + \n",
    "    geom_vline(xintercept = 0.31, color = 'red') +\n",
    "    geom_point() +\n",
    "    theme_classic()\n",
    "align_cov_SNPdens_highQualOnly_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath <- snakemake@output[[4]]\n",
    "ggsave(filename = outpath, plot = align_cov_SNPdens_highQualOnly_plot, device = 'pdf', \n",
    "       height = 8, width = 8, units = 'in', dpi = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe for samples to be removed\n",
    "\n",
    "- Create a dataframe with names of samples to be removed for use in Snakemake pipeline\n",
    "    - Total of 88 samples being removed for some analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples not in high quality sample dataframe\n",
    "samples_to_remove <- allQC_data %>% \n",
    "    filter(!(Sample %in% allQC_data_highQualOnly$Sample)) %>% \n",
    "    dplyr::select(Sample)\n",
    "head(samples_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick breakdown of number of samples being tossed by habitab and city\n",
    "sample_df <- suppressMessages(read_csv('../resources/low1_libraryConcentrations.csv')) %>% \n",
    "    dplyr::select(city, site, plantID) %>% \n",
    "    rename('Sample' = 'plantID')\n",
    "\n",
    "# Join sample_df to samples_to_remove and summarise\n",
    "samples_to_remove_counts <- samples_to_remove %>% \n",
    "    left_join(., sample_df, by = 'Sample') %>% \n",
    "    group_by(city, site) %>% \n",
    "    summarise(to_remove = n())\n",
    "samples_to_remove_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = snakemake@output[[5]]\n",
    "write_delim(file = outpath, x = samples_to_remove_counts, col_names = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = snakemake@output[[6]]\n",
    "write_delim(file = outpath, x = samples_to_remove, col_names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
